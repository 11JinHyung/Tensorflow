{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "\n",
      "MNIST 데이터 전송 완료\n",
      "\n",
      "WARNING:tensorflow:From <ipython-input-3-5e9039b825df>:42 in <module>.: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n",
      "예측 정확도 : 91.69%\n"
     ]
    }
   ],
   "source": [
    "#_*_ coding: utf-8 _*_\n",
    "# Tesorflow 에서 제공하는 Mnist 데이터를 쉽게 가져오는 tutorial\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import tensorflow as tf\n",
    "\n",
    "# Mnist 데이터 셋\n",
    "\n",
    "# mnist.train(55,000 개의 훈련 데이터)\n",
    "# mnist.validation(5000개의 검증 데이터)\n",
    "\n",
    "# 데이터.images 혹은 데이터.labels 와 같이 사용\n",
    "# 각각의 이미지는 28*28(784) pixel 이고 label은 0~9 까지의 숫자\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
    "print(\"\\nMNIST 데이터 전송 완료\\n\")\n",
    "\n",
    "# Placeholder > session의 값들을 변수로 사용 가능\n",
    "# x : 784개의 픽셀\n",
    "# y : 10개의 라벨(0 ~ 9)\n",
    "x = tf.placeholder(tf.float32, [None, 784])\n",
    "y = tf.placeholder(tf.float32, [None, 10])\n",
    "\n",
    "# Tensorflow를 이용한 작업\n",
    "# 로지스틱 회귀\n",
    "# pred = softmax(W*X + b) = 여러개의 sigmoid 값들을 모두 더한 값으로 나누어 전체 label 확률의 합이 1이 되도록 하는 것(가장 큰 확률 Label이 선택됨)\n",
    "# W,b : weight = 0 으로 초기화\n",
    "W = tf.Variable(tf.zeros([784, 10]))\n",
    "b = tf.Variable(tf.zeros([10]))\n",
    "\n",
    "pred = tf.nn.softmax(tf.matmul(x, W) + b)\n",
    "\n",
    "# http://blog.naver.com/PostView.nhn?blogId=laonple&logNo=220554852626\n",
    "cross_entropy = tf.reduce_mean(-tf.reduce_sum(y * tf.log(pred), reduction_indices=[1]))\n",
    "\n",
    "# 훈련 step은 cross_entropy를 최소화하는 수준으로 설정\n",
    "# 정답 예측은 카테고리(0~9) 답변이기에 같은지 다른지만 확인\n",
    "# 예측 정확도는 정답 예측의 정도를 RMS 한 값\n",
    "train_step = tf.train.GradientDescentOptimizer(0.5).minimize(cross_entropy)\n",
    "correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(pred, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "# Tensorflow 세션 실행\n",
    "init = tf.initialize_all_variables()\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "for i in range(1000):\n",
    "  # Batch Size를 설정하는 것으로 한번에 한개씩 학습하는 것이 아니라 여러 데이터 셋을 한번에 학습할 수 있다\n",
    "  # 장점 :\n",
    "  # Batch Size를 설정하고 반복마다 다음 train set을 넘겨줌\n",
    "  batch_xs, batch_ys = mnist.train.next_batch(100)\n",
    "  sess.run(train_step, feed_dict={x: batch_xs, y: batch_ys})\n",
    "\n",
    "print(\"예측 정확도 : \" + str(round(sess.run(accuracy, feed_dict={x: mnist.test.images, y: mnist.test.labels})*100,2)) + \"%\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
